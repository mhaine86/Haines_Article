\documentclass{article}

\usepackage{Sweave}
\begin{document}
\input{Article-concordance}

\title{Treasure Island Wordcloud}
\author{Matthew Haines}
\maketitle

\begin{abstract}
This PDF will contain a wordcloud and title of the book 'Treasure Island' by Robert Louis Stevenson.

\end{abstract}

\textit{Treasure Island}

\section{packages}
This section will contain the packages which will then be used to load 'Treasure Island', manipulate string and form wordclouds.

\begin{Schunk}
\begin{Sinput}
> package<-c('dplyr')
> library(tidytext)
> library(tm)
> library(wordcloud)
> library(stringr)
> library(dplyr)
> library(knitr)
> library(gutenbergr)
\end{Sinput}
\end{Schunk}

The first step is to determine the id of Treasure Island:

\begin{Schunk}
\begin{Sinput}
> gutenberg_works()%>%
+   select(gutenberg_id,title,author)%>%
+   filter(title=='Treasure Island')
\end{Sinput}
\begin{Soutput}
# A tibble: 1 x 3
  gutenberg_id           title                  author
         <int>           <chr>                   <chr>
1          120 Treasure Island Stevenson, Robert Louis
\end{Soutput}
\end{Schunk}

\noindent In the resulting tibble from the code above, one can pick out the id of the book; 120.

\section{Chapter 1}

Here I want to isolate the 'chapter 1' block of text
\begin{Schunk}
\begin{Sinput}
> library(stringr)
> df <- gutenberg_download(120)
> head(df[str_detect(df$text, '^CHAPTER'),],n=1)$text
\end{Sinput}
\begin{Soutput}
character(0)
\end{Soutput}
\end{Schunk}


\section{The Wordcloud}
Next we will create a database of all the words in Treasure Island.
\begin{Schunk}
\begin{Sinput}
> words_df<-df%>%
+   unnest_tokens(word,text)
> words_df
\end{Sinput}
\begin{Soutput}
# A tibble: 69,111 x 2
   gutenberg_id      word
          <int>     <chr>
 1          120  treasure
 2          120    island
 3          120        by
 4          120    robert
 5          120     louis
 6          120 stevenson
 7          120  treasure
 8          120    island
 9          120        to
10          120     s.l.o
# ... with 69,101 more rows
\end{Soutput}
\end{Schunk}

Using dplyr, we can remove stop and insigificant words. Then using the word cloud package we can compile the words into a wordcloud. 
\begin{Schunk}
\begin{Sinput}
> words_df<-words_df%>%
+   filter(!(word %in% stop_words$word))
> words_free <- words_df%>%
+   group_by(word)%>%
+   summarise(count = n())%>%
+   arrange(-count)
> wordcloud(words_free$word, words_free$count, min.freq = 25)
\end{Sinput}
\end{Schunk}


\end{document}
